{"cells":[{"metadata":{},"cell_type":"markdown","source":"First of all, I would like to show my appreciation to the owners' of the follwoing Notebooks that were extremly helpful:\nhttps://www.kaggle.com/allunia/santander-customer-transaction-eda\nhttps://www.kaggle.com/gpreda/santander-eda-and-prediction\nhttps://www.kaggle.com/jiweiliu/lgb-2-leaves-augment\n\n# Part 1 - EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n#import lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')\nrandom_state = 42\nnp.random.seed(random_state)\nfrom sklearn.model_selection import cross_validate\n# visualization\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_load(filename):\n    return pd.read_csv(filename)\n\ndef basic_EDA(df):\n    size = df.shape\n    sum_duplicates = df.duplicated().sum()\n    sum_null = df.isnull().sum().sum()\n    return print(\"Number of Samples: %d,\\nNumber of Features: %d,\\nDuplicated Entries: %d,\\nNull Entries: %d\" %(size[0],size[1], sum_duplicates, sum_null))\n\n#Plot Bar graph with all classes and percentages - Return number of Classes and Samples per class\ndef bar_plot(df, target):\n    unique, counts = np.unique(target, return_counts = True)\n    label = np.zeros(len(unique))\n    for i in range(len(unique)):\n        label[i] = (counts[i]/df.shape[0])*100\n        plt.bar(unique,counts, color = ['burlywood', 'green'], edgecolor='black')\n        plt.text(x = unique[i]-0.15, y = counts[i]+0.01*df.shape[0], s = str(\"%.2f%%\" % label[i]), size = 15)\n    plt.ylim(0, df.shape[0])\n    plt.xticks(unique)\n    plt.xlabel(\"Target\")\n    plt.ylabel(\"Count\")\n    plt.show()\n    return unique, counts\n\n#Plots Heatmap and top 10 and bottom correlated features\ndef feat_corr_analysis(corrmat):\n    f, ax = plt.subplots(figsize =(9, 8)) \n    #1 Heatmap\n    sns.heatmap(corrmat, vmin=0, vmax=0.2, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1)\n    plt.title(\"Heatmap - Correlation between data variables\")\n    #2 Correlation Values and Features\n    correlations = corrmat.abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n    correlations = correlations[correlations['level_0'] != correlations['level_1']]\n    #Top 10 correlated features\n    correlations.tail(10)\n    #Bottom 10 correlated features\n    correlations.head(10)\n    return correlations.tail(10)\n\ndef feat_corr_distr(train,test):\n    #Plot distribution of Feature Correlation\n    train_corr_distr = train.values.flatten()\n    train_corr_distr = train_corr_distr[train_corr_distr != 1]\n    test_corr_distr = test.values.flatten()\n    test_corr_distr = test_corr_distr[test_corr_distr != 1]\n    plt.figure(figsize=(20,5))\n    sns.distplot(train_corr_distr, color=\"Red\", label=\"Train\")\n    sns.distplot(test_corr_distr, color=\"black\", label=\"Test\")\n    plt.xlabel(\"Correlation values\")\n    plt.ylabel(\"Density\")\n    plt.title(\"Feature Correlation\"); \n    plt.legend();\n    \ndef prediction(x_train,y_train):\n    classifier.fit(x_train,y_train)\n    y_proba = classifier.predict_proba(x_train)\n    plt.figure(figsize=(20,5))\n    y_pred = classifier.predict(x_train)\n    y_proba = classifier.predict_proba(x_train)\n    score = roc_auc_score(y_train, y_pred)\n    return y_proba, score\n\ndef probability_class(y_proba):\n    plt.figure(figsize=(20,5))\n    sns.distplot(y_proba[y_train==1,1], label=\"True Class 1\")\n    sns.distplot(y_proba[y_train==0,1], label=\"True Class 0\")\n    plt.xticks(np.arange(0,1, 0.1))\n    plt.xlabel(\"Predicted probability values of class 1\")\n    plt.ylabel(\"Density\")\n    plt.title(\"Predicted probability values of class 1 against the true Target\"); \n    plt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the Training and Test set CSV files."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Data\ntrain = data_load('../input/santander-customer-transaction-prediction/train.csv')\ntest = data_load('../input/santander-customer-transaction-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overview\nFor an overview of the data, the function outputs the number of samples, features, duplicated and null values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"***Train EDA***\")\ntrain_EDA = basic_EDA(train)\nprint(\"***Test EDA***\")\ntest_EDA  = basic_EDA(test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a large dataset, with 200.000 samples and over 200 features. No null values or duplicated entries were found, eliminating the need for data cleanse at this stage. It is also important to understand the type of variables present in this dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The \"target\" column contains the true labels. The \"ID_CODE\" is the object dtype mentioned in the info(). Other than this, all values are numeric so there is no need for enconding. This is true for train and test set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()\ntest.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, it is possible to remove the ID_code column and replace it with a numerical index that can be easily handled by the ML models. The new column is called Id."},{"metadata":{"trusted":true},"cell_type":"code","source":"#ID_Code is the only object dtype. It can be replaced by index values\ntrain[\"Id\"] = train.index.values\ntest[\"Id\"] = test.index.values\ninit_train_ID = train.ID_code.values\ninit_test_ID = test.ID_code.values\ntrain.drop(\"ID_code\", axis=1, inplace=True)\ntest.drop(\"ID_code\", axis=1, inplace=True)\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Samples per Class\nBy analysing the samples per class ratio it is possible to see the class imbalance issue. Almost 90% of the samples are clients that did not performed the transaction. An initial attempt was made to use SMOTE and ADASYN as oversampling methods. Preliminary test have shown that this did not helped the model to generalise to the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"##Visualise Class Imbalance - Training Set\nnum_classes, feat_per_class = bar_plot(train, train[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Correlation\nSince this dataset has a significant amount of features, correlated helps to develop an understanding on how the variable relate to each other. This can indicate starting points for feature engineering and the most relevant variables for the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_corrmat = train.drop([\"target\"], axis=1).corr()\nfeat_corr_train = feat_corr_analysis(train_corrmat)\ntest_corrmat = test.corr()\nfeat_corr_test = feat_corr_analysis(test_corrmat)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is none or very little correlation between the features for training and test sets. The plot below shows that the correlation values distribution is similar for the train and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_corr_distr(train_corrmat, test_corrmat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2 - Model Baseline\nRandom Forest (RF) algorithm is used as a starting point to allow better understanding of this dataset. RF is quick, it does not have that many parameters to tune and usually provide reasonable results. By understanding what works and what does not works with RF, it is possible to improve the model quicker and then try other algorithms. This first step is mainly to understand the top important features, apply feature engineering and sampling techniques."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare DF\nX_train = train.drop(\"target\", axis=1).values\ny_train = train.target.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is the RF classifier. Grid Search supported the selection of the initial parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Baseline Model\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(n_estimators = 10, \n                       criterion = 'gini',\n                       max_depth = 15, \n                       max_features = 'auto', \n                       min_samples_leaf = 1, \n                       random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code below creates the RF model and outputs the AUC result for the training set. It also outputs the probabilities of each sample belonging to class 0 or 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_y_proba, RF_model_score = prediction(X_train,y_train)\nprint(\"Baseline RF: %.2f \"%(RF_model_score))\npd.DataFrame(RF_y_proba).describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF_y_proba contains the probabilites of class 0 and 1 for every sample. Most values for class 1 are small and the majority does not reach 0.1, as shown by the table above. One hypthesis can be that the usual threshold of 0.5 is not ideal for this model to assign class 1 or 0. One way to visualise this is to plot the \"Class 1\" probability distribution for all samples, according to their True label. "},{"metadata":{"trusted":true},"cell_type":"code","source":"probability_class(RF_y_proba)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above it is possible to extract the following insights:\n* Most of the True Class 1 samples were predicted by our model with a probability lower than 0.5\n* Most of the True Class 0 samples are concentrated within the values of 0 and 0.15\n* For samples with Class 1 probability values higher than approximately 0.15, it is almost safe to say they are True Class 1. Altough there is the orange bump around 0.17\n* It is possible to perform a quick test and see if this helps the model accuracy:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#From the graph, used a threshold of 0.15\nthreshold = 0.15\ny_pred = np.zeros(RF_y_proba.shape[0])\ny_pred[RF_y_proba[:,1] >= threshold] = 1\nRFT_model_score = roc_auc_score(y_train, y_pred)\nprint(\"Baseline RF: %.2f \\nThreshold RF: %.2f\"%(RF_model_score, RFT_model_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A 30% increase in accuracy was achieved by this simple but effective strategy. This is something to keep in mind in the future and check if other models also present this behaviour."},{"metadata":{},"cell_type":"markdown","source":"## Feature Importances\nThis analysis can helps reduce the number of features while mantaining the minimum impact on model accuracy. Using the RF classifier, the following features are more effective to our model:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = classifier.feature_importances_\nindices = np.argsort(importances)[::-1]\ncolors = plt.cm.Reds(importances)\n# Plot the feature importances\nplt.figure(1, figsize=(40,20))\nplt.title(\"Feature importances\")\nsns.barplot(x=indices, y=importances[indices], order = indices,palette=\"Blues_d\")\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"To improve visualisation, narrowing down:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#From the Feature Importances, we can see that \nn_top = 50\nidx = np.argsort(importances)[::-1][0:n_top]\nfeature_names = train.drop(\"target\", axis=1).columns.values\nplt.figure(figsize=(20,5))\nsns.barplot(x=feature_names[idx], y=importances[idx],palette=\"Blues_d\");\nplt.title(\"Top important features to start\");\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_train[:,idx]).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next model is built using the top 50 features. Additional features were created performing the following operations per row: "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_top = X_train[:,0:n_top]\nsum_feat= X_train_top.sum(axis=1)\nmin_feat = X_train_top.min(axis=1)\nmax_feat = X_train_top.max(axis=1)\nmean_feat = X_train_top.mean(axis=1)\nstd_feat = X_train_top.std(axis=1)\nX_train_top = np.concatenate((X_train_top,\n                             sum_feat[:,None],\n                             min_feat[:,None],\n                             max_feat[:,None],\n                             mean_feat[:,None],\n                             std_feat[:,None]),\n                             axis = 1)\nRF1_y_proba, RF1_model_score = prediction(X_train_top, y_train)\nprobability_class(RF1_y_proba)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the new features, is necessary to revaluate and assign a new threshold "},{"metadata":{"trusted":true},"cell_type":"code","source":"RF1_y_pred = np.zeros(RF1_y_proba.shape[0])\nRF1_y_pred[RF1_y_proba[:,1] >= 0.12] = 1\nRF1_model_score = roc_auc_score(y_train, y_pred)\nprint(\"Baseline RF %.2f\\nThreshold RF %.2f\\nThreshold RF with only top features %.2f\"%(RF_model_score, RFT_model_score, RF1_model_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 3 - Submission\nBy reducing the number of features to a quarter of the original model, the same accuracy was mantained. At this point is interesting to check our score in the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_top = X_test[:,idx]\nX_test_top = X_test[:,0:n_top]\nsum_feat= X_test_top.sum(axis=1)\nmin_feat = X_test_top.min(axis=1)\nmax_feat = X_test_top.max(axis=1)\nmean_feat = X_test_top.mean(axis=1)\nstd_feat = X_test_top.std(axis=1)\nX_test_top = np.concatenate((X_test_top,\n                             sum_feat[:,None],\n                             min_feat[:,None],\n                             max_feat[:,None],\n                             mean_feat[:,None],\n                             std_feat[:,None]),\n                             axis = 1)\n#####################################################\ny_proba = classifier.predict_proba(X_test_top)\ny_pred = np.zeros(y_proba.shape[0])\ny_pred[y_proba[:,1] >= 0.12] = 1\nsubmission = pd.concat([pd.DataFrame(init_test_ID),pd.DataFrame(y_pred)],axis = 1)\nsubmission.columns = ['ID_code', 'Target']\nsubmission.to_csv(\"submission_RForest.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This concludes a quick analysis on the Santander Customer Transaction Challenge. The result on the test set points to overfitting, since it only achieved 0.59.\nOn the following days, I want to devote more attention to other models and improve feature engineering. I noticed many challenge submissions using Light GBM and ANN. It is also essential to implement an ensemble, as this usually improves the overall model score."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}